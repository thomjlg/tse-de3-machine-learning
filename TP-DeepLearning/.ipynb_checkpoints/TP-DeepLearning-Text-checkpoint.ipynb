{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep learning - DE3 final Lab (Evaluation) \n",
    "\n",
    "This project belongs to the NLP domain. The task is straightforward: assign the correct job category to a job description. This is thus a multi-class classification task with 28 classes to choose from.\n",
    "The data has been retrieved from CommonCrawl. The latter has been famously used to train OpenAI's GPT-3 model. The data is therefore representative of what can be found on the English speaking part of the Internet. The goal of this project is to design a solution that accurate to predict the job based on the job descriptions. \n",
    "\n",
    "## Evaluation\n",
    "\n",
    "First of all, solutions are evaluated according to the Macro F1 metric, The Macro F1 score is simply the arithmetic average of the F1 score for each class.\n",
    "\n",
    "## Datasets\n",
    "\n",
    "**data.json**\n",
    "Contains job descriptions as well as genders for the training set, which contains 217,197 samples. If you're using pandas, then you can easily open this with pd.read_json.\n",
    "\n",
    "**label.csv**\n",
    "Contains job labels for the training set.\n",
    "\n",
    "**categories_string.csv**\n",
    "Provides a mapping between job labels and label integers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import modules\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline 1 (no deep learning)\n",
    "\n",
    "For this part we propose to train and test a straightforward logistic regression model on the tf-idf vectors extracted from the corpus. We are not applying any particular pre-processing to start and will progressively try to reduce the dimension of the vocabulary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read all three files to obtain three dataframes (pandas)\n",
    "\n",
    "# read train.json\n",
    "df = pd.read_json('data/train.json')\n",
    "\n",
    "# read label\n",
    "label = pd.read_csv('data/label.csv')\n",
    "\n",
    "# read categories_string\n",
    "categories = pd.read_csv('data/categories_string.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>description</th>\n",
       "      <th>gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>She is also a Ronald D. Asmus Policy Entrepre...</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>He is a member of the AICPA and WICPA. Brent ...</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Dr. Aster has held teaching and research posi...</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>He runs a boutique design studio attending cl...</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4</td>\n",
       "      <td>He focuses on cloud security, identity and ac...</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id                                        description gender\n",
       "0   0   She is also a Ronald D. Asmus Policy Entrepre...      F\n",
       "1   1   He is a member of the AICPA and WICPA. Brent ...      M\n",
       "2   2   Dr. Aster has held teaching and research posi...      M\n",
       "4   3   He runs a boutique design studio attending cl...      M\n",
       "5   4   He focuses on cloud security, identity and ac...      M"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the 3 first rows of each dataframe\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id  Category\n",
       "0   0        19\n",
       "1   1         9\n",
       "2   2        19"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>pastor</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>model</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>yoga_teacher</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              0  1\n",
       "0        pastor  0\n",
       "1         model  1\n",
       "2  yoga_teacher  2"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categories.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a column in df based on the column Category from the label dataframe\n",
    "#df['label'] = label['Category']\n",
    "df = pd.merge(df, label, on='Id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>description</th>\n",
       "      <th>gender</th>\n",
       "      <th>Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>She is also a Ronald D. Asmus Policy Entrepre...</td>\n",
       "      <td>F</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>He is a member of the AICPA and WICPA. Brent ...</td>\n",
       "      <td>M</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Dr. Aster has held teaching and research posi...</td>\n",
       "      <td>M</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id                                        description gender  Category\n",
       "0   0   She is also a Ronald D. Asmus Policy Entrepre...      F        19\n",
       "1   1   He is a member of the AICPA and WICPA. Brent ...      M         9\n",
       "2   2   Dr. Aster has held teaching and research posi...      M        19"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize the distribution of the gender attribute and the Category one using appropriate graphics (barplot)\n",
    "# Example of visualisation libraries: seaborn, matplotlib etc. \n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "graph_gender = sns.countplot(x=\"gender\", data=df)\n",
    "plt.show()\n",
    "graph_category = sns.countplot(x=\"Category\", data=df)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What do you observe ?**\n",
    "\n",
    "Your answer: Données très inégales, cela risque de fausser le modèle, mais en moyenne ça sera ok"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the following part, let's focus on the top-5 jobs (category). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19, 26, 20, 14, 6]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>description</th>\n",
       "      <th>gender</th>\n",
       "      <th>Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>100766</th>\n",
       "      <td>100766</td>\n",
       "      <td>She joined the K-State faculty in August of 2...</td>\n",
       "      <td>F</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140783</th>\n",
       "      <td>140783</td>\n",
       "      <td>He received his B.A. in Political Science alo...</td>\n",
       "      <td>M</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215277</th>\n",
       "      <td>215277</td>\n",
       "      <td>She completed her graduate studies at Univers...</td>\n",
       "      <td>F</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121801</th>\n",
       "      <td>121801</td>\n",
       "      <td>Prior to this, she was working with IBS Hyder...</td>\n",
       "      <td>F</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137100</th>\n",
       "      <td>137100</td>\n",
       "      <td>For a long while his research has focused in ...</td>\n",
       "      <td>M</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178054</th>\n",
       "      <td>178054</td>\n",
       "      <td>His research applies lab and field experiment...</td>\n",
       "      <td>M</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105860</th>\n",
       "      <td>105860</td>\n",
       "      <td>In addition to working as a visiting nurse, s...</td>\n",
       "      <td>F</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59119</th>\n",
       "      <td>59119</td>\n",
       "      <td>She also has a degree in music and teaches mu...</td>\n",
       "      <td>F</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128236</th>\n",
       "      <td>128236</td>\n",
       "      <td>His research interests include cinema and cul...</td>\n",
       "      <td>M</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33940</th>\n",
       "      <td>33940</td>\n",
       "      <td>His research focuses on public sector contrac...</td>\n",
       "      <td>M</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Id                                        description gender  \\\n",
       "100766  100766   She joined the K-State faculty in August of 2...      F   \n",
       "140783  140783   He received his B.A. in Political Science alo...      M   \n",
       "215277  215277   She completed her graduate studies at Univers...      F   \n",
       "121801  121801   Prior to this, she was working with IBS Hyder...      F   \n",
       "137100  137100   For a long while his research has focused in ...      M   \n",
       "178054  178054   His research applies lab and field experiment...      M   \n",
       "105860  105860   In addition to working as a visiting nurse, s...      F   \n",
       "59119    59119   She also has a degree in music and teaches mu...      F   \n",
       "128236  128236   His research interests include cinema and cul...      M   \n",
       "33940    33940   His research focuses on public sector contrac...      M   \n",
       "\n",
       "        Category  \n",
       "100766        19  \n",
       "140783        26  \n",
       "215277        19  \n",
       "121801        19  \n",
       "137100        19  \n",
       "178054        19  \n",
       "105860        14  \n",
       "59119          6  \n",
       "128236        19  \n",
       "33940         19  "
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a new dataframe based on `df` but that contains observations that belongs to the top-5 most frequent jobs. \n",
    "top_values = df['Category'].value_counts()\n",
    "liste = top_values.nlargest(5).index.tolist()\n",
    "print(liste)\n",
    "df_top5 = df[df['Category'].isin(liste)]\n",
    "\n",
    "df_top5.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-141-ce13b2bc1df9>:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_top5[\"description_lower\"] = [x.lower() for x in df_top5.description]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>description</th>\n",
       "      <th>gender</th>\n",
       "      <th>Category</th>\n",
       "      <th>description_lower</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>24770</th>\n",
       "      <td>24770</td>\n",
       "      <td>With a strong theory in lighting technique, h...</td>\n",
       "      <td>M</td>\n",
       "      <td>20</td>\n",
       "      <td>with a strong theory in lighting technique, h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31530</th>\n",
       "      <td>31530</td>\n",
       "      <td>His main interest is the role of streams, riv...</td>\n",
       "      <td>M</td>\n",
       "      <td>19</td>\n",
       "      <td>his main interest is the role of streams, riv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216708</th>\n",
       "      <td>216708</td>\n",
       "      <td>Her professional work has been in the corpora...</td>\n",
       "      <td>F</td>\n",
       "      <td>19</td>\n",
       "      <td>her professional work has been in the corpora...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128044</th>\n",
       "      <td>128044</td>\n",
       "      <td>Her research explores the intersection of rac...</td>\n",
       "      <td>F</td>\n",
       "      <td>19</td>\n",
       "      <td>her research explores the intersection of rac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51216</th>\n",
       "      <td>51216</td>\n",
       "      <td>Energized by blue-sky ideation and fulfilled ...</td>\n",
       "      <td>M</td>\n",
       "      <td>6</td>\n",
       "      <td>energized by blue-sky ideation and fulfilled ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Id                                        description gender  \\\n",
       "24770    24770   With a strong theory in lighting technique, h...      M   \n",
       "31530    31530   His main interest is the role of streams, riv...      M   \n",
       "216708  216708   Her professional work has been in the corpora...      F   \n",
       "128044  128044   Her research explores the intersection of rac...      F   \n",
       "51216    51216   Energized by blue-sky ideation and fulfilled ...      M   \n",
       "\n",
       "        Category                                  description_lower  \n",
       "24770         20   with a strong theory in lighting technique, h...  \n",
       "31530         19   his main interest is the role of streams, riv...  \n",
       "216708        19   her professional work has been in the corpora...  \n",
       "128044        19   her research explores the intersection of rac...  \n",
       "51216          6   energized by blue-sky ideation and fulfilled ...  "
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lets convert the text to lower case to reduce the size of the vocabulary\n",
    "df_top5[\"description_lower\"] = [x.lower() for x in df_top5.description]\n",
    "df_top5.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into train and test \n",
    "X_train, X_test, y_train, y_test = train_test_split(df_top5[\"description_lower\"], \n",
    "                                                    df_top5[\"Category\"], test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NB features: 121369\n"
     ]
    }
   ],
   "source": [
    "# Convert the text to tf-idf vectors \n",
    "transformer = TfidfVectorizer()\n",
    "transformer.fit(X_train.values)\n",
    "print(\"NB features: %d\" %(len(transformer.vocabulary_)))\n",
    "X_train = transformer.transform(X_train.values)\n",
    "X_test = transformer.transform(X_test.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape is :  (86027, 121369)\n",
      "y_train shape is :  (86027,)\n"
     ]
    }
   ],
   "source": [
    "# Check the shape of X_train and y_train\n",
    "print(\"X_train shape is : \", X_train.shape)\n",
    "print(\"y_train shape is : \", y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit a logistic regression model on X_train with 2000 max iterations\n",
    "model = LogisticRegression(max_iter=2000)\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Macro F1:  0.897\n"
     ]
    }
   ],
   "source": [
    "# Check the macro f1-score\n",
    "test_f1 = f1_score(y_test, y_pred, average='macro')\n",
    "print('Macro F1:  %0.3f' % test_f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What about pre-processing ? \n",
    "\n",
    "Let's try basic pre-processing for textual data. \n",
    "- removing stop words\n",
    "- lemmatization \n",
    "- stemmatization \n",
    "\n",
    "To proceed we can use the `nltk` library for instance (other alternatives : `sklearn`, `spacy`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/thomasjaulgey/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
     ]
    }
   ],
   "source": [
    "# Import nltk and the list of stop words\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "stop = stopwords.words('english')\n",
    "\n",
    "# Take a look at the list\n",
    "print(list(stop))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-150-3ae3d652e350>:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_top5['description_wo_stop'] = df_top5[\"description_lower\"].apply(\n"
     ]
    }
   ],
   "source": [
    "# Remove stop words from df \n",
    "df_top5['description_wo_stop'] = df_top5[\"description_lower\"].apply(\n",
    "    lambda words: ' '.join(word.lower() for word in words.split() if word not in stop))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df_top5[\"description_wo_stop\"], \n",
    "                                                    df_top5[\"Category\"], test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NB features: 121237\n"
     ]
    }
   ],
   "source": [
    "# Tf-idf vectorization\n",
    "transformer = TfidfVectorizer(stop_words=list(stop)).fit(X_train.values)\n",
    "print(\"NB features: %d\" %(len(transformer.vocabulary_)))\n",
    "X_train = transformer.transform(X_train.values)\n",
    "X_test = transformer.transform(X_test.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Macro F1:  0.897\n"
     ]
    }
   ],
   "source": [
    "# Logistic regression - Same as before\n",
    "model = LogisticRegression(max_iter=2000)\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "test_f1 = f1_score(y_test, y_pred, average='macro')\n",
    "print('Macro F1:  %0.3f' % test_f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What do you observe ?**\n",
    "\n",
    "Your answer : mêmes performances du modèle mais on a moins de variables, donc potentiel gain de temps de calcul sans dégrader les performances du modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let add some more pre-processing. \n",
    "\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.stem import WordNetLemmatizer,PorterStemmer\n",
    "import re\n",
    "\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stemmer = PorterStemmer() \n",
    "\n",
    "def preprocess(sentence):\n",
    "    sentence=str(sentence)\n",
    "    # Lowercase text\n",
    "    sentence = sentence.lower()\n",
    "    # Remove whitespace\n",
    "    sentence=sentence.replace('{html}',\"\") \n",
    "    cleanr = re.compile('<.*?>')\n",
    "    cleantext = re.sub(cleanr, '', sentence)\n",
    "    # Remove weblinks\n",
    "    rem_url=re.sub(r'http\\S+', '',cleantext)\n",
    "    # Remove numbers\n",
    "    rem_num = re.sub('[0-9]+', '', rem_url)\n",
    "    tokenizer = RegexpTokenizer(r'\\w+')\n",
    "    tokens = tokenizer.tokenize(rem_num)  \n",
    "    filtered_words = [w for w in tokens if len(w) > 2 if not w in stopwords.words('english')]\n",
    "    stem_words=[stemmer.stem(w) for w in filtered_words]\n",
    "    lemma_words=[lemmatizer.lemmatize(w) for w in stem_words]\n",
    "    return \" \".join(filtered_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Describe the different pre-processing methods used by the `preprocess` function**\n",
    "\n",
    "Your answer: \n",
    "- texte en minuscule\n",
    "- suppressions des espaces en trop\n",
    "- suppression des liens web\n",
    "- suppression des nombres\n",
    "- suppression des mots de moins de 2 lettres et des stop words de plus de 2 lettres pour ne garder que le texte important"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-155-ea35781f4fd4>:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_top5['description_pre']=df_top5['description'].map(lambda s:preprocess(s))\n"
     ]
    }
   ],
   "source": [
    "# Let's apply the function to our data\n",
    "df_top5['description_pre']=df_top5['description'].map(lambda s:preprocess(s)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following the same steps as before, split the data into a train and a test set. They learn a logistic regression and print the f1 score obtained. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NB features: 111665\n",
      "Macro F1:  0.894\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df_top5[\"description_pre\"], \n",
    "                                                    df_top5[\"Category\"], test_size=0.33, random_state=42)\n",
    "\n",
    "# Tf-idf vectorization\n",
    "transformer = TfidfVectorizer(stop_words=list(stop)).fit(X_train.values)\n",
    "print(\"NB features: %d\" %(len(transformer.vocabulary_)))\n",
    "X_train = transformer.transform(X_train.values)\n",
    "X_test = transformer.transform(X_test.values)\n",
    "\n",
    "# Logistic regression - Same as before\n",
    "model = LogisticRegression(max_iter=2000)\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "test_f1 = f1_score(y_test, y_pred, average='macro')\n",
    "print('Macro F1:  %0.3f' % test_f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What do you observe ?**\n",
    "\n",
    "Your answer: score identique aux précédents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's try to tune the regularisation parameter of our model. \n",
    "\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Initialize the model\n",
    "...\n",
    "\n",
    "# Define the grid search\n",
    "...\n",
    "\n",
    "# Summarize results\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's dive into Deep Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformers and attention mechanisms\n",
    "The paper ‘Attention Is All You Need’ describes transformers and what is called a \n",
    "sequence-to-sequence architecture. Sequence-to-Sequence (or Seq2Seq) is a neural net that transforms\n",
    "a given sequence of elements, such as the sequence of words in a sentence, into another sequence. \n",
    "\n",
    "Seq2Seq models are particularly good at translation, where the sequence of words from one language is transformed into a sequence of different words in another language. A popular choice for this type of model is Long-Short-Term-Memory (LSTM)-based models. With sequence-dependent data, the LSTM modules can give meaning to the sequence while remembering (or forgetting) the parts it finds important (or unimportant). Sentences, for example, are sequence-dependent since the order of the words is crucial for understanding the sentence. LSTM are a natural choice for this type of data.\n",
    "\n",
    "Seq2Seq models consist of an Encoder and a Decoder. The Encoder takes the input sequence and maps it into a higher dimensional space (n-dimensional vector). That abstract vector is fed into the Decoder which turns it into an output sequence. The output sequence can be in another language, symbols, a copy of the input, etc. To solve the task of document classification we will use the pre-trained model **Bert**. \n",
    "\n",
    "#### TO DO \n",
    "\n",
    "1. As a first exercice, you will have to read the paper **Attention Is All You Need**, to get a general understanding of transformers. You can also look for additional resources online (tutorial, video etc.) To keep things clear I recommend to focus on transformers for NLP (text). The paper can be found [here](https://proceedings.neurips.cc/paper/2017/file/3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf). \n",
    "\n",
    "**This step is mandatory as you will need to unserstand the basics of transformers for what will follow. In addition, you will have questions specifically related to this architecture during your last evaluation.**\n",
    "\n",
    "2. We will then use a pre-trained model based usin the popular [Huggin Face](https://huggingface.co/docs/transformers/index) for pytorch. More precisely, we plan on using the [Bert](https://huggingface.co/docs/transformers/model_doc/bert) model. The following cells guide you toward using Bert. On top of applying the model to our data, you will have to answer a few questions along the project (including the ones above). These **questions are mandatory**. \n",
    "\n",
    "3. Finally, the last step is the fine-tuning. Generally speaking, fine tuning a model refers to re-training the last layers of a deep architecture on your data. Again, you will be guided on how to proceed. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Lets start !**\n",
    "The first thing that you need to do is to install the transformers librariy \n",
    "\n",
    "`import sys\n",
    "!{sys.executable} -m pip install transformers`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the library\n",
    "from transformers import AutoModelWithLMHead, AutoTokenizer\n",
    "import torch \n",
    "from transformers import BertTokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at some popular pre-trained models available in Huggingface. \n",
    "\n",
    "1. We start with the model Camembert [Camembert](https://camembert-model.fr/) trained on french corpus by Facebook and Inria teams. \n",
    "2. GPT2 a pre-trained model for text generation\n",
    "3. Bert !\n",
    "\n",
    "**Note:** You can also directly try the online [demo](https://transformer.huggingface.co/) of the library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 1 - Camembert\n",
    "\n",
    "model_name = \"camembert-base\"# try also distilbert-base-cased for english\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelWithLMHead.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_sequences = [f\"Jacques Chirac est un {tokenizer.mask_token}\", \n",
    "            f\"Antoine Griezman est un {tokenizer.mask_token}\",\n",
    "            f\"Le camembert, c'est {tokenizer.mask_token}\"]\n",
    "\n",
    "for sequence in all_sequences:\n",
    "    input = tokenizer.encode(sequence, return_tensors=\"pt\")\n",
    "    mask_token_index = torch.where(input == tokenizer.mask_token_id)[1]\n",
    "    token_logits = model(input).logits\n",
    "    mask_token_logits = token_logits[0, mask_token_index, :]\n",
    "    top_5_tokens = torch.topk(mask_token_logits, 5, dim=1).indices[0].tolist()\n",
    "    for token in top_5_tokens:\n",
    "        print(sequence.replace(tokenizer.mask_token, tokenizer.decode([token])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 2 - GPT2 for text generation \n",
    "\n",
    "# Your turn : find a small example on how to use GPT2 to generate text with pytorch. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finally, Bert !! Let's see next time :) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
